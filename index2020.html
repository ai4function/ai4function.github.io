<!DOCTYPE html>
<html lang="en"> 
<head>
	<title>AI4Function 2020</title>
	
	<!-- Meta -->
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="description" content="Bootstrap 4 Tech Conference Template">
	<meta name="author" content="Xiaoying Riley at 3rd Wave Media">    
    <meta name="google-site-verification" content="a1hb1EziMcoN_PVc7DQ80TrV-8KAIRq99UrKXoFaaCg" />
	<link rel="shortcut icon" href="favicon.ico"> 
	
	<!-- Google Font -->
	<link href="https://fonts.googleapis.com/css?family=Montserrat:600,700,800|Roboto:300,400,700&display=swap" rel="stylesheet">
	
	<!-- FontAwesome JS-->
	<script defer src="assets/fontawesome/js/all.min.js"></script>

	<!-- Theme CSS -->  
	<link id="theme-style" rel="stylesheet" href="assets/css/theme.css">
	<link id="theme-style" rel="stylesheet" href="assets/css/ai4function.css">


</head> 

<body>    
	<header id="header" class="header fixed-top">	    
		<div class="branding">
			<div class="container-fluid">
				<nav class="main-nav navbar navbar-expand-lg">
					<!--<div class="site-logo"><a class="scrollto" href="#hero-block"><img class="logo-icon" src="assets/images/logo-white.svg" alt="logo"></a></div>    -->
					
                    <!--
					<div class="navbar-btn order-lg-2"><a class="btn btn-secondary" href="https://themes.3rdwavemedia.com/bootstrap-templates/startup/devconf-free-bootstrap-4-conference-template-for-tech-conferences-and-events/" target="_blank">Tickets</a></div>
                    -->
					
					<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navigation" aria-controls="navigation" aria-expanded="false" aria-label="Toggle navigation">
						<span class="navbar-toggler-icon"></span>
					</button>
					
					<div id="navigation" class="navbar-collapse collapse  justify-content-lg-end mr-lg-3">
						<ul class="nav navbar-nav">
							
							<li class="nav-item"><a class="nav-link scrollto" href="#about-section">About</a></li>                                              
							<li class="nav-item"><a class="nav-link scrollto" href="#schedule-section">Schedule</a></li>                                              
							<li class="nav-item"><a class="nav-link scrollto" href="#cfp-section">Call for Papers</a></li>
                            <li class="nav-item"><a class="nav-link" href="https://easychair.org/conferences/?conf=ai4function" target="_blank">Submit your Work</a></li>
							<li class="nav-item"><a class="nav-link scrollto" href="#organization-section">Organization</a></li>
						</ul><!--//nav-->
					</div><!--//navabr-collapse-->

				</nav><!--//main-nav-->
				
			</div><!--//container-->
		</div><!--//branding-->
	</header><!--//header-->
	
	<div id="hero-block" class="hero-block">
		<div id="hero-carousel" class="hero-carousel carousel slide carousel-fade" data-ride="carousel">
			<div class="carousel-inner">
				<div class="carousel-item-1 carousel-item active">
				</div>
                <!-- Carousel image from https://en.wikipedia.org/wiki/File:Allam_Medical_Building.jpg -->
                <!--
				<div class="carousel-item-2 carousel-item">
				</div>
				<div class="carousel-item-3 carousel-item">
				</div>
                -->
			</div>
		</div>
		<div class="hero-block-mask"></div>
		<div class="container">
			<div class="hero-text-block" id="header-wrapper">
				<h1 class="hero-heading mb-2">First Workshop on Artificial Intelligence for Function, Disability, and Health</h1>
				<div class="hero-meta mb-3"><i class="far fa-calendar-alt mr-2"></i>January 7-8, 2021 12AM-3AM UTC <br /><i>(January 6-7 PM in Americas)</i></div>
                <div class="hero-meta mb-3"><i class="fas fa-map-marker-alt mr-2"></i>Virtual</div>
				<div class="hero-intro mb-4">An <a class="text-white" href="https://www.ijcai20.org/">IJCAI-PRICAI 2020</a> workshop</div>
                <!--
				<div class="hero-cta"><a class="btn btn-primary btn-lg" href="https://themes.3rdwavemedia.com/bootstrap-templates/startup/devconf-free-bootstrap-4-conference-template-for-tech-conferences-and-events/" target="_blank">Get Tickets</a></div>
                -->
				
			</div><!--//hero-text-block-->
		</div><!--//container-->

	</div><!--//hero-block-->
	
    <!--
	<div class="stats-block theme-bg-primary text-white py-4 text-center">
		<div class="container">
			<div class="row">
				<div class="col-6 col-md-3">
					<div class="item">
						<div class="number">2000+</div>
						<div class="unit">Attendees</div>
					</div>
				</div>
				<div class="col-6 col-md-3">
					<div class="item">
						<div class="number">3</div>
						<div class="unit">Days</div>
					</div>
				</div>
				<div class="col-6 col-md-3">
					<div class="item">
						<div class="number">60+</div>
						<div class="unit">Talks</div>
					</div>
				</div>
				<div class="col-6 col-md-3">
					<div class="item">
						<div class="number">10+</div>
						<div class="unit">Workshops</div>
					</div>
				</div>
			</div>
		</div>
	</div>
    -->

	<section id="about-section" class="about-section section theme-bg-light">
		<div class="container">
            <!--
            <div class="alert alert-warning" id="covid-update" style="width:70%; margin-left: auto; margin-right: auto; margin-bottom: 30px;">
                <div class="text-center"><h5>Deadline Extension</h5></div>
                <p>
                (2020-06-06) Due to the coronavirus crisis, IJCAI-PRICAI 2020 has been <a href="http://ijcai20.org">delayed until January 2021</a>.  The AI4Function workshop will be held together with IJCAI-PRICAI at that time, in a physical or virtual format.
                </p>
                <p>
                In order to support dissemination of authors' new research results, we will be publishing the proceedings of the AI4Function workshop as planned in Summer 2020.  To accommodate our community's needs during this time, <strong>we have extended our submission deadline an additional two weeks to June 19.</strong>
                </p>
            </div>
            -->
            <div class="alert alert-warning" style="width:70%;margin-left: auto;margin-right:auto;margin-bottom:30px;text-align:center;">
                <h4><a href="http://ceur-ws.org/Vol-2760/">AI4Function 2020 proceedings</a> are live!</h4>
            </div>
			<h3 class="section-heading text-center mb-3">About AI4Function</h3>
			<div class="section-intro single-col-max mx-auto mb-4">
                The <strong>First Workshop on Artificial Intelligence for Function, Disability, and Health (AI4Function 2020)</strong>
                addresses the role of Artificial Intelligence (AI) technologies in collecting and analyzing information on function and
                disability.  Function, as the &quot;lived experience of health&quot;, describes physical and mental wellness at the
                whole-person level, and is a key indicator for global health. Better information on function is critical in light of
                global demographic shifts and increases in chronic conditions, and AI technologies are well-poised to address this need.
                This workshop brings together members of the AI and health communities interested in function to chart the course of
                this area of research.
            </div>
			<div class="benefits-list text-center mb-3">
				<h4 class="text-center mb-4">Why Join Us</h4>
				<ul class="list-unstyled text-left d-inline-block">
					<li><i class="fas fa-check-circle mr-2"></i>Showcase your original research on AI and function/disability</li>
					<li><i class="fas fa-check-circle mr-2"></i>Present your previous research to a new audience</li>
					<li><i class="fas fa-check-circle mr-2"></i>Learn from other research from around the world</li>
					<li><i class="fas fa-check-circle mr-2"></i>Set the course of research on AI for functional status information</li>
				</ul>
			</div><!--//benefits-list-->
            <!--
			<div class="event-countdown text-center mb-3">		   
				<h4 class="countdown-intro mb-2 text-center mb-3">Event Starts In:</h4>
				<div id="countdown-box" class="countdown-box"></div>
			</div>
            -->
            <div class="about-cta text-center mb-5"><a href="https://ijcai20.org/register/" class="btn btn-secondary btn-lg mb-5" target="_blank">Register (Choose W05)</a></div>
			<!--<div class="about-cta text-center mb-5"><a class="btn btn-secondary btn-lg  mb-5" href="https://easychair.org/conferences/?conf=ai4function" target="_blank">Submit Your Work</a></div>-->
		</div><!--//container-->
    </section>
	
	<div class="container">
		<hr>
	</div>

	<section id="schedule-section" class="schedule-section section">
		<div class="container">
			<h3 class="section-heading text-center mb-5">Schedule</h3>

            <div class="container" id="time-zone-disclaimer">
                <p>As the workshop is being held virtually, all times are given in Universal Coordinated Time (UTC).</p>
                <p>Corresponding times for world locations:</p>
                <ul>
                    <li>Eastern United States: UTC-5 (<b>7 - 10pm Jan 6 and Jan 7</b>)</li>
                    <li>Central United States: UTC-6 (<b>6 - 9pm Jan 6 and Jan 7</b>)</li>
                    <li>Pacific United States: UTC-8 (<b>4 - 7pm Jan 6 and Jan 7</b>)</li>
                    <li>Western Europe: UTC+1 (<b>1 - 4am Jan 7 and Jan 8</b>)</li>
                    <li>Malaysia/China Standard Time: UTC+8 (<b>8 - 11am Jan 7 and Jan 8</b>)</li>
                    <li>Japan: UTC+9 (<b>9am - 12pm Jan 7 and Jan 8</b>)</li>
                </ul>
            </div>
			
			<!-- Nav tabs -->
			<ul class="schedule-nav nav nav-pills nav-fill" id="myTab" role="tablist">
				<li class="nav-item mr-2">
					<a class="nav-link active" id="tab-1" data-toggle="tab" href="#tab-1-content" role="tab" aria-controls="tab-1-content" aria-selected="true">
						<span class="heading">Day 1</span>
						<span class="meta">(Thursday 7 January - Europe/Africa/Asia)</span>
						<span class="meta">(Wednesday 6 January - Americas)</span>
					</a>
				</li>
				<li class="nav-item mr-2">
					<a class="nav-link" id="tab-2" data-toggle="tab" href="#tab-2-content" role="tab" aria-controls="tab-2-content" aria-selected="false">
						<span class="heading">Day 2</span>
						<span class="meta">(Friday 8 January - Europe/Africa/Asia)</span>
						<span class="meta">(Thurdsay 7 January - Americas)</span>
					</a>
				</li>
			</ul>
			
			<!-- Tab panes -->
			<div class="schedule-tab-content tab-content">
				<div class="tab-pane active" id="tab-1-content" role="tabpanel" aria-labelledby="tab-1">
					<div class="item item-talk">
						<div class="meta">
							<h4 class="time mb-3">12:00AM - 12:30AM UTC</h4>
						</div><!--//meta-->
						<div class="content">
							<h3 class="title mb-3">Opening Remarks</h3>
                            <div class="desc">AI4Function 2020 Organizing Committee</div>
						</div><!--//content-->
					</div><!--//item-->
					<div class="item item-talk">
						<div class="meta">
							<h4 class="time mb-3">12:30AM - 1:30AM UTC</h4>
						</div><!--//meta-->
						<div class="content">
							<h3 class="title mb-3">Keynote Presentation: Digital Health Sciences: from Discovery to Delivery in Health care AI</h3>
                            <div class="desc author-list"><a href="https://www.mayo.edu/research/faculty/liu-hongfang-ph-d/bio-00055092">Hongfang Liu, PhD</a> <i>Professor of Biomedical Informatics and Chair, Division of Digital Health Sciences, Department of Health Sciences Research, Mayo Clinic</i></div>
                            <div class="desc">
                                <a href="#modal-keynote" data-toggle="modal" data-target="#modal-keynote" class="btn btn-primary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Abstract</a>
                            </div>
						</div><!--//content-->
					</div><!--//item-->
					<div class="item item-other">
						<div class="meta">
							<h4 class="time mb-3">1:30AM - 2:00AM UTC</h4>
						</div><!--//meta-->
						<div class="content">
							<h3 class="title mb-3">Break</h3>
						</div><!--//content-->
					</div><!--//item-->
					<div class="item item-talk">
						<div class="meta">
							<h4 class="time mb-3">2:00AM - 2:20AM UTC</h4>
						</div><!--//meta-->
						<div class="content">
							<h3 class="title mb-3">Variability in General Health Status Post Liver Transplantation</h3>
                            <div class="desc author-list">Lisiane Pruinelli, Alana Schmiesing, Michelle James, Michelle Mathianson-Moore, Jesse Schold, Gyorgy Simon</div>
                            <div class="desc">
                                <a href="#modal-paper-1" data-toggle="modal" data-target="#modal-paper-1" class="btn btn-primary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Abstract</a>
                                <a href="http://ceur-ws.org/Vol-2760/paper1.pdf" class="btn btn-secondary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Paper PDF</a>
                            </div>
						</div><!--//content-->
					</div><!--//item-->
					<div class="item item-talk">
						<div class="meta">
							<h4 class="time mb-3">2:20AM - 2:40AM UTC</h4>
						</div><!--//meta-->
						<div class="content">
							<h3 class="title mb-3">Challenges of developing a natural language processing method with electronic health records to identify persons with chronic mobility disability</h3>
                            <div class="desc author-list">Nicole Agaronnik, Charlotta Lindvall, Areej El-Jawahri, Wei He, Lisa Iezzoni</div>
                            <div class="desc">
                                <a href="#modal-abstract-1" data-toggle="modal" data-target="#modal-abstract-1" class="btn btn-primary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Abstract</a>
                            </div>
						</div><!--//content-->
					</div><!--//item-->
					<div class="item item-talk">
						<div class="meta">
							<h4 class="time mb-3">2:40AM - 3:00AM UTC</h4>
						</div><!--//meta-->
						<div class="content">
							<h3 class="title mb-3">Conversational Agent for Daily Living Assessment Coaching</h3>
                            <div class="desc author-list">Aditya Gaydhani, Raymond Finzel, Sheena Dufresne, Maria Gini, Serguei Pakhomov </div>
                            <div class="desc">
                                <a href="#modal-paper-2" data-toggle="modal" data-target="#modal-paper-2" class="btn btn-primary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Abstract</a>
                                <a href="http://ceur-ws.org/Vol-2760/paper2.pdf" class="btn btn-secondary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Paper PDF</a>
                            </div>
						</div><!--//content-->
					</div><!--//item-->
					<div class="item item-talk">
						<div class="meta">
							<h4 class="time mb-3">3:00AM - 3:10AM UTC</h4>
						</div><!--//meta-->
						<div class="content">
							<h3 class="title mb-3">Day 1 Closing Remarks</h3>
                            <div class="desc">AI4Function 2020 Organizing Committee</div>
						</div><!--//content-->
					</div><!--//item-->
					
				</div><!--//tab-1-content-->
				<div class="tab-pane no-timeline" id="tab-2-content" role="tabpanel" aria-labelledby="tab-2">
					<div class="item item-talk">
						<div class="meta">
							<h4 class="time mb-3">12:00AM - 12:10AM UTC</h4>
						</div><!--//meta-->
						<div class="content">
							<h3 class="title mb-3">Day 2 Opening Remarks</h3>
                            <div class="desc">AI4Function 2020 Organizing Committee</div>
						</div><!--//content-->
					</div><!--//item-->
					<div class="item item-talk">
						<div class="meta">
							<h4 class="time mb-3">12:10AM - 12:30AM UTC</h4>
						</div><!--//meta-->
						<div class="content">
							<h3 class="title mb-3">Person-Independent Multimodal Emotion Detection for Children with High-Functioning Autism</h3>
                            <div class="desc author-list">Annanda Sousa, Mathieu d’Aquin, Manel Zarrouk, Jennifer Holloway </div>
                            <div class="desc">
                                <a href="#modal-paper-3" data-toggle="modal" data-target="#modal-paper-3" class="btn btn-primary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Abstract</a>
                                <a href="http://ceur-ws.org/Vol-2760/paper3.pdf" class="btn btn-secondary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Paper PDF</a>
                            </div>
						</div><!--//content-->
					</div><!--//item-->
					<div class="item item-talk">
						<div class="meta">
							<h4 class="time mb-3">12:30AM - 12:50AM UTC</h4>
						</div><!--//meta-->
						<div class="content">
							<h3 class="title mb-3">Assistive Mobile Application for the Blind</h3>
                            <div class="desc author-list">Ismail Sahak, Huey Fang Ong, Syuhada Abdul Rahman </div>
                            <div class="desc">
                                <a href="#modal-paper-4" data-toggle="modal" data-target="#modal-paper-4" class="btn btn-primary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Abstract</a>
                                <a href="http://ceur-ws.org/Vol-2760/paper4.pdf" class="btn btn-secondary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Paper PDF</a>
                            </div>
						</div><!--//content-->
					</div><!--//item-->
					<div class="item item-other">
						<div class="meta">
							<h4 class="time mb-3">12:50AM - 1:00AM UTC</h4>
						</div><!--//meta-->
						<div class="content">
							<h3 class="title mb-3">Break</h3>
						</div><!--//content-->
					</div><!--//item-->
					<div class="item item-talk">
						<div class="meta">
							<h4 class="time mb-3">1:00AM - 2:00AM UTC</h4>
						</div><!--//meta-->
						<div class="content">
							<h3 class="title mb-3">Panel Discussion: Next Steps and Future Directions for AI for Function and Disability</h3>
                            <div class="desc">
                                <p><a href="https://smhs.gwu.edu/biomedinfo/faculty-and-staff">Qing Zeng, PhD</a> <i>Director, Biomedical Informatics Center &amp; Professor, Department of Clinical Research and Leadership, George Washington University</i></p>
                                <p><a href="https://www.ot.wustl.edu/about/our-people/chih-hung-chang-156">Chih-Hung Chang, PhD</a> <i>Professor of Occupational Therapy, Medicine and Orthopaedic Surgery, Washington University in St. Louis</i></p>
                                <p><a href="https://mghmonganhealthpolicy.org/faculty/about-dr-iezzoni/">Lisa Iezzoni, MD, MSc</a> <i>Professor of Medicine, Harvard Medical School</i></p>
                                <p><a href="https://profiles.dom.pitt.edu/dgim/faculty_info.aspx/Jonassaint6454">Charles Jonassaint, PhD MHS</a> <i>Assistant Professor of Medicine, Social Work and Clinical and Translational Science, University of Pittsburgh</i></p>
                                <p class="panel-sponsor">
                                    <i>Panel discussion generously sponsored by the <a href="https://www.nichd.nih.gov/about/org/ncmrr">National Center for Medical Rehabilitation Research (NCMRR)</a></i><br />
                                    <img src="https://www.nichd.nih.gov/themes/custom/nichd/images/NICHD_logo.svg" />
                                </p>
                            </div>
						</div><!--//content-->
					</div><!--//item-->
					<div class="item item-other">
						<div class="meta">
							<h4 class="time mb-3">2:00AM - 2:10AM UTC</h4>
						</div><!--//meta-->
						<div class="content">
							<h3 class="title mb-3">Break</h3>
						</div><!--//content-->
					</div><!--//item-->
					<div class="item item-talk">
						<div class="meta">
							<h4 class="time mb-3">2:10AM - 2:30AM UTC</h4>
						</div><!--//meta-->
						<div class="content">
							<h3 class="title mb-3">Privacy-Preserving Monitoring System with Ultra Low-Resolution Infrared Sensor</h3>
                            <div class="desc author-list">Miyuki Ogata, Shogo Murakami, Takumi Mikura, Ikuko Eguchi Yairi </div>
                            <div class="desc">
                                <a href="#modal-paper-5" data-toggle="modal" data-target="#modal-paper-5" class="btn btn-primary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Abstract</a>
                                <a href="http://ceur-ws.org/Vol-2760/paper5.pdf" class="btn btn-secondary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Paper PDF</a>
                            </div>
						</div><!--//content-->
					</div><!--//item-->
					<div class="item item-talk">
						<div class="meta">
							<h4 class="time mb-3">2:30AM - 2:50AM UTC</h4>
						</div><!--//meta-->
						<div class="content">
							<h3 class="title mb-3">Building a Mobility Dictionary for Whole-Person Functional Assessment</h3>
                            <div class="desc author-list">Ayah Zirikly, Bart Desmet, Denis Newman-Griffis, Pei-Shu Ho, Jonathan Camacho Maldonado, Maryanne Sacco, Julia Porcino </div>
                            <div class="desc">
                                <a href="#modal-abstract-2" data-toggle="modal" data-target="#modal-abstract-2" class="btn btn-primary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Abstract</a>
                            </div>
						</div><!--//content-->
					</div><!--//item-->
					<div class="item item-talk">
						<div class="meta">
							<h4 class="time mb-3">2:50AM - 3:00AM UTC</h4>
						</div><!--//meta-->
						<div class="content">
							<h3 class="title mb-3">Closing Remarks</h3>
                            <div class="desc">AI4Function 2020 Organizing Committee</div>
						</div><!--//content-->
					</div><!--//item-->
				</div><!--//tab-2-content-->
			</div><!--//schedule-tab-content-->
			<div class="schedule-cta text-center mx-auto">
              <!--  <a href="https://themes.3rdwavemedia.com/bootstrap-templates/startup/devconf-free-bootstrap-4-conference-template-for-tech-conferences-and-events/" class="btn btn-primary btn-lg mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Download Schedule</a>-->
                <a href="https://ijcai20.org/register/" class="btn btn-secondary btn-lg d-block d-md-inline-block" target="_blank">Register (Choose W05)</a></div>
		</div><!--//container-->
	</section><!--//schedule-section-->

    <section id="cfp-section" class="cfp-section section">
		<div class="media-block theme-bg-primary py-5">
			<div class="container">
				<h3 class="section-heading text-center mb-5 text-white">Call for Papers</h4>
                <div class="important-dates text-center mb-3">
                    <h4 class="text-center mb-4 text-white">Important Dates</h4>
                    <h5 class="text-white"><i>All times are anywhere on Earth (AoE)</i></h5>
                    <ul class="list-unstyled text-left d-inline-block">
                        <!--<li><i class="fas fa-circle-notch mr-2"></i><a href="mailto:ai4function@gmail.com">Let organizers know</a>: <i>If you're thinking about submitting!</i></li>-->
                        <li><i class="fas fa-circle-notch mr-2"></i>Submissions due: <i><del>May 6, 2020</del></i> <strong>June 19, 2020</strong> <i>(extended)</i></li>
                        <li><i class="fas fa-circle-notch mr-2"></i>Notification of acceptance: <i><del>June 3, 2020</del></i> <strong>July 14, 2020</strong></li>
                        <li><i class="fas fa-circle-notch mr-2"></i>Camera-ready versions due: <i><del>June 24, 2020</del></i> <strong>July 24, 2020</strong></li>
                        <li><i class="fas fa-circle-notch mr-2"></i>Workshop: <i><del>July 12, 2020</del></i> <strong>January 2021 (Date TBD)</strong></li>
                    </ul>
                </div>
                <div class="desc">
                    <h4 class="text-white mb-3">Description</h4>
                    <p class="text-white">
                        The First Workshop on Artificial Intelligence for Function, Disability, and Health (AI4Function 2020) invites the submission of abstracts, short and long papers describing research that focuses on applying informatics methods, artificial intelligence (AI) or data mining techniques in the area of whole-person care, disability, and functional status information.  Functional Status Information (FSI) describes physical and mental wellness at the whole-person level (as opposed to the cellular or organ level), and includes information on activity performance, social role participation, and environmental and personal factors that affect well-being and quality of life.  Collecting and analyzing this information is critical to addressing the data needs in caring for aging global populations, and providing effective care for individuals with chronic conditions, multi-morbidity, and disability.  However, FSI has proven difficult to capture systematically within existing paradigms, leaving a space ripe for technological innovation. AI4Function is a venue for researchers cutting across data science and AI methods to discuss new ways to collect and utilize FSI within healthcare delivery, public health, and social well-being.
                    </p>
                </div>
                <h4 class="text-white mb-3">Topics</h4>
                <div class="row">
                    <div class="desc col-12 col-md-6 mb-2">
                        <p class="text-white mb-2">Relevant topics for the workshop include, but are not limited to:</p>
                        <ul class="list-unstyled text-left d-inline-block text-white">
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Informatics methods applied to FSI, including information extraction, information retrieval, and classification of FSI (e.g. mobility, self-care, mental functioning)</li>
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Applications of AI for functional status measurement</li>
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Usage of FSI to model health outcomes/resource utilization</li>
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Terminologies and ontologies related to functional status</li>
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Analysis of FSI data (e.g., language data, wearable measurements)</li>
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Combinations of multi-modal data to capture functional status</li>
                        </ul>
                    </div>
                    <div class="desc col-12 col-md-3 mb-2">
                        <p class="text-white">Data sources of interest include, but are not limited to:</p>
                        <ul class="list-unstyled text-left d-inline-block text-white">
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Medical records</li>
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Disability and work programs </li>
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Health and human services data</li>
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Wearable devices</li>
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Social media</li>
                        </ul>
                    </div>
                    <div class="desc col-12 col-md-3 mb-2">
                        <p class="text-white">Targeted data types include, but are not limited to:</p>
                        <ul class="list-unstyled text-left d-inline-block text-white">
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Unstructured (free text) narrative</li>
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Structured medical data (e.g., lab reports, range of motion assessments) </li>
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Semi-structured reports (e.g., state welfare visit reports)</li>
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Standardized clinical surveys (e.g., PROMIS, AM-PAC, PHQ-9)</li>
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Population surveys</li>
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Wearable device measurements</li>
                            <li><i class="fas fa-chevron-circle-right mr-2"></i>Video and audio recordings</li>
                        </ul>
                    </div>
                </div>
                <div class="desc text-white">
                    <h4 class="mb-3 text-white">Submission Instructions</h4>
                    <p>
                        All submissions to AI4Function should be <span class="text-underline">anonymous</span> using the EasyChair submission site.
                        Submissions should follow IJCAI-PRICAI 2020 formatting guidelines; LaTeX and Word templates are available in the <a class="text-white" href="https://www.ijcai.org/authors_kit">IJCAI authors kit</a>.
                    </p>
                    <div class="container text-center">
                    <a class="btn btn-secondary btn-md" href="https://easychair.org/conferences/?conf=ai4function" target="_blank">Take me to EasyChair!</a>
                    </div>
                    <p>
                        <br/>
                        At least one author of each accepted paper/abstract must register for and attend the workshop. 
                    </p>
                    <p>We invite the following types of submissions:</p>
                    <ul class="list-unstyled text-left d-inline-block text-white">
                        <li><i class="fas fa-check-circle mr-2"></i><strong>Long papers</strong> are no longer than seven pages in total: six pages for
                            the main body of the paper (including figures), and one additional page for references that don’t fit in the six body pages.
                            Long papers are expected to describe reports of original, unpublished research.</li>
                        <li><i class="fas fa-check-circle mr-2"></i><strong>Short papers</strong> follow a 4+1 format, up to four pages for the body of
                            the paper and one page for references that don’t fit within the four-page limit.  Short papers are appropriate for preliminary results, work in progress, etc.</li>
                        <li><i class="fas fa-check-circle mr-2"></i><strong>Abstracts</strong> are a maximum of two pages, including references.
                            Unlike long/short papers, abstracts can describe previously-published research, and are a great way to present recent work to a new audience or show
                            work in progress.<br />
                            <i>For abstracts, a 75-word maximum short description should be provided when submitting your abstract, but does not need to be included in the PDF.</i></li>
                    </ul>
                    <p>Authors are required to submit their papers in PDF format. Papers that are not properly anonymized or are longer than the page limit will be rejected without review.</p>
                    <p>
                        All submissions to AI4Function will go through a double-blind reviewing process. Accepted abstracts
                        will be presented in the poster session. Accepted papers will be presented as either a talk or a poster,
                        depending on the reviewers’ recommendations. Accepted short and long papers will be published in the
                        workshop proceedings on <a class="text-white" href="http://ceur-ws.org/">CEUR-WS</a>. We are exploring a journal track for
                        extended versions of accepted papers (TBC).
                    </p>
                    <p>
                        All individuals involved in the AI4Function review process must adhere to the IJCAI conflict of interest policy. Details can be found at <a class="text-white" href="http://ijcai.org/">the IJCAI website</a>.
                    </p>
                    <p>Have any questions about submissions?<div class="container text-center"><a class="btn btn-secondary btn-md mb-2" href="mailto:ai4function@gmail.com">Email ai4function@gmail.com!</a></div></p>
                </div>
                <!--
				<div class="section-intro text-center single-col-max mx-auto text-white mb-5">Conference videos and images from previous years is a great way to show people what to expect at the conference and entice them to join. You can host more media content on YouTube, Flickr or Instagram and link out to them in this section.</div>
				<div class="row">
					<div class="col-12 col-md-6 mb-3">
						<div class="embed-responsive embed-responsive-16by9">
							
							<iframe width="560" height="315" src="https://www.youtube.com/embed/stjniziaxy4" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
						</div>
					</div>
					<div class="col-12 col-md-6 mb-md-5">
						<div class="embed-responsive embed-responsive-16by9">
							<iframe class="embed-responsive-item" src="https://www.youtube.com/embed/NPYqnGNO_zw" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
						</div>
					</div>
				</div>
                -->
			</div><!--//container-->
		</div><!--//media-block-->
	</section><!--//about-section-->
	
	<section id="organization-section" class="organization-section section">
		<div class="container">
			<h3 class="section-heading text-center mb-3">Organizing Committee</h3>
			<div class="row">
				<div class="col-12 col-md-6 col-lg-3 mb-4">
					<div class="card rounded-0">
						<a href="https://drgriffis.github.io"><img src="assets/images/organizers/denis.jpg" class="card-img-top rounded-0" alt=""></a>
						<div class="card-body">
							<h5 class="card-title mb-2">Denis Newman-Griffis</h5>
							<div class="card-text mb-3">
								<div class="meta">University of Pittsburgh</div>
								<div class="meta">National Institutes of Health Clinical Center</div>
							</div><!--//card-text-->
						</div><!--//card-->
					</div><!--//card-->
				</div><!--//col-->
				<div class="col-12 col-md-6 col-lg-3 mb-4">
					<div class="card rounded-0">
						<a href="https://healthinformatics.umn.edu/bio/ihi-faculty-staff/serguei-pakhomov"><img src="assets/images/organizers/serguei.jpg" class="card-img-top rounded-0" alt=""></a>
						<div class="card-body">
							<h5 class="card-title mb-2">Serguei V Pakhomov</h5>
							<div class="card-text mb-3">
								<div class="meta">University of Minnesota</div>
							</div><!--//card-text-->
						</div><!--//card-->
					</div><!--//card-->
				</div><!--//col-->
				<div class="col-12 col-md-6 col-lg-3 mb-4">
					<div class="card rounded-0">
						<a href="https://web.stanford.edu/~stamang/"><img src="assets/images/organizers/suzanne.jpg" class="card-img-top rounded-0" alt=""></a>
						<div class="card-body">
							<h5 class="card-title mb-2">Suzanne Tamang</h5>
							<div class="card-text mb-3">
								<div class="meta">Stanford University</div>
							</div><!--//card-text-->
						</div><!--//card-->
					</div><!--//card-->
				</div><!--//col-->
				<div class="col-12 col-md-6 col-lg-3 mb-4">
					<div class="card rounded-0">
						<a href="https://ayahzirikly.wordpress.com/"><img src="assets/images/organizers/ayah.jpg" class="card-img-top rounded-0" alt=""></a>
						<div class="card-body">
							<h5 class="card-title mb-2">Ayah Zirikly</h5>
							<div class="card-text mb-3">
								<div class="meta">Johns Hopkins University</div>
								<div class="meta">National Institutes of Health Clinical Center</div>
							</div><!--//card-text-->
						</div><!--//card-->
					</div><!--//card-->
				</div><!--//col-->
				<div class="col-12 col-md-6 col-lg-3 mb-4">
					<div class="card rounded-0">
						<a href="https://scholar.google.com/citations?user=gDaEBRIAAAAJ&hl=en&oi=sra"><img src="assets/images/organizers/bart.jpg" class="card-img-top rounded-0" alt=""></a>
						<div class="card-body">
							<h5 class="card-title mb-2">Bart Desmet</h5>
							<div class="card-text mb-3">
								<div class="meta">National Institutes of Health Clinical Center</div>
							</div><!--//card-text-->
						</div><!--//card-->
					</div><!--//card-->
				</div><!--//col-->
				<div class="col-12 col-md-6 col-lg-3 mb-4">
					<div class="card rounded-0">
						<a href="https://www.mayo.edu/research/faculty/liu-hongfang-ph-d/bio-00055092"><img src="assets/images/organizers/hongfang.jpg" class="card-img-top rounded-0" alt=""></a>
						<div class="card-body">
							<h5 class="card-title mb-2">Hongfang Liu</h5>
							<div class="card-text mb-3">
								<div class="meta">Mayo Clinic</div>
							</div><!--//card-text-->
						</div><!--//card-->
					</div><!--//card-->
				</div><!--//col-->
				<div class="col-12 col-md-6 col-lg-3 mb-4">
					<div class="card rounded-0">
						<a href="https://www.airc.aist.go.jp/en/intro/ "><img src="assets/images/organizers/junichi.jpg" class="card-img-top rounded-0" alt=""></a>
						<div class="card-body">
							<h5 class="card-title mb-2">Junichi Tsujii</h5>
							<div class="card-text mb-3">
								<div class="meta">AIST, Japan</div>
							</div><!--//card-text-->
						</div><!--//card-->
					</div><!--//card-->
				</div><!--//col-->
                <!--
				<div class="col-12 col-md-6 col-lg-3 mb-4">
					<div class="card rounded-0">
						<a href="#modal-speaker-1" data-toggle="modal" data-target="#modal-speaker-1"><img src="assets/images/speakers/speaker-2.jpg" class="card-img-top rounded-0" alt=""></a>
						<div class="card-body">
							<h5 class="card-title mb-2">Sarah Doe</h5>
							<div class="card-text mb-3">
								<div class="meta">Developer Advocate</div>
								<div class="meta">Google</div>
							</div>
							<a href="#modal-speaker-1" data-toggle="modal" data-target="#modal-speaker-1">Read more &rarr;</a>
						</div>
						<div class="card-footer text-muted">
							<ul class="social-list list-inline mb-0">
								<li class="list-inline-item"><a  href="#"><i class="fab fa-twitter fa-fw"></i></a></li>
								<li class="list-inline-item"><a  href="#"><i class="fab fa-linkedin-in fa-fw"></i></a></li>
								<li class="list-inline-item"><a  href="#"><i class="fab fa-github fa-fw"></i></a></li>
							</ul>
						</div>
					</div>
				</div>
                -->
				</div><!--//col-->
			</div><!--//row-->
		</div><!--//container-->
		<div class="container">
			<h3 class="section-heading text-center mb-3">Program Committee</h3>
            <ul>
                <li>Steven Bedrick, Oregon Health and Science University</li>
                <li>Jonathan Camacho Maldonado, National Institutes of Health Clinical Center</li>
                <li>Guy Divita, National Institutes of Health Clinical Center</li>
                <li>Tome Eftimov, Jozef Stefan Institute </li>
                <li>Reuben Escorpizo, University of Vermont</li>
                <li>Milena Gianfresco, University of California at San Francisco</li>
                <li>Kerri Gogolin, Sensentia</li>
                <li>Christine Herlihy, GTRI</li>
                <li>Pei-Shu Ho, National Institutes of Health Clinical Center</li>
                <li>Zara Izadi, University of California at San Francisco</li>
                <li>Josephine Jacobs, Veterans Administration</li>
                <li>Rafael Jimenez Silva, National Institutes of Health Clinical Center</li>
                <li>Albert M Lai, Washington University in St. Louis</li>
                <li>Young Ji Lee, University of Pittsburgh</li>
                <li>Beth Marfeo, Tufts University</li>
                <li>Christine McDonough, University of Pittsburgh</li>
                <li>Bibek Paudel, Stanford University</li>
                <li>Beth Prusaczyk, Washington University in St. Louis</li>
                <li>Elizabeth Rasch, National Institutes of Health Clinical Center</li>
                <li>Angus Roberts, King’s College London </li>
                <li>Carolyn Penstein Rosé, Carnegie Mellon University</li>
                <li>Maryanne Sacco, National Institutes of Health Clinical Center</li>
                <li>Sunghwan Sohn, Mayo Clinic</li>
                <li>Robert Stewart, King’s College London</li>
                <li>Sumithra Velupillai, King’s College London</li>
            </ul>
        </div>
	</section><!--//organization-section-->

	<footer class="footer py-5 theme-bg-primary">
		<div class="container text-center">
			
			<ul class="social-list list-inline mb-4"> 
				<li class="list-inline-item mr-3"><a href="mailto:ai4function@gmail.com"><i class="fas fa-envelope"></i></a></li>
				<li class="list-inline-item mr-3"><a href="https://twitter.com/hashtag/ai4function2020?f=tweets&vertical=default&src=hash"><i class="fab fa-twitter fa-fw"></i></a></li>
			</ul><!--//social-list-->
			
			
            <!--
			<ul class="footer-links list-inline mx-auto mb-4">
				<li class="list-inline-item"><a href="#">Code of Conduct</a></li>
				<li class="list-inline-item">|</li>
				<li class="list-inline-item"><a href="#">Terms</a></li>
				<li class="list-inline-item">|</li>
				<li class="list-inline-item mr-0"><a href="#">Privacy</a></li>
			</ul>--><!--//footer-link-->
			
			<!--/* This template is released under the Creative Commons Attribution 3.0 License. Please keep the attribution link below when using for your own project. Thank you for your support. :) If you'd like to use the template without the attribution, you can buy the commercial license via our website: themes.3rdwavemedia.com */-->
			<small class="copyright">Designed with <i class="fas fa-heart" style="color: #EC645E;"></i> by <a href="http://themes.3rdwavemedia.com" target="_blank">Xiaoying Riley</a> for developers</small>
			
		</div><!--//container-->	    
	</footer>

	<!-- Modal Speaker -->
	<div class="modal modal-speaker modal-paper-1" id="modal-paper-1" tabindex="-1" role="dialog" aria-labelledby="paper-1-ModalLabel" aria-hidden="true">
		<div class="modal-dialog">
			<div class="modal-content">
				<div class="modal-header">
					<button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
					<h4 id="paper-1-ModalLabel" class="modal-title sr-only">Variability in General Health Status Post Liver Transplantation</h4>
				</div>
				<div class="modal-body p-0">
					<div class="media flex-column flex-md-row theme-bg-light p-4 p-lg-5">
						<div class="media-body text-center text-md-left mx-auto">
							<h2 class="name mb-2">Variability in General Health Status Post Liver Transplantation</h2>
							<div class="meta">Lisiane Pruinelli, Alana Schmiesing, Michelle James, Michelle Mathianson-Moore, Jesse Schold, Gyorgy Simon</div>
                            <div class="meta"><i class="far fa-calendar-alt mr-2"></i>2:00 - 2:20AM UTC, January 7 2021</div>
						</div><!--//media-body-->
					</div><!--//media-->
					
					<div class="desc p-4 p-lg-5">
                        <p>Transplantation outcomes focus has shifted beyond
                        increasing survival to decreasing the negative effects of liver disease, focusing on outcomes related
                        to physical and social health. These measures have
                        been studied as isolated variables, but they have
                        not been examined as a cluster of recipient characteristics, representing their wellbeing. This paper
                        aims to compare liver transplantation recipient’s
                        general health status pre- and 2-years post-liver
                        transplant, and to examine whether age, gender,
                        race, and comorbidities are associated with better
                        health status post-transplant. We used data derived
                        from electronic health records of recipients 18
                        years or older who underwent liver transplantation
                        between 01/01/2008 and 3/31/2017. We excluded
                        recipients who died within 2 years from transplant
                        or did not have follow-up data. A Cox proportional
                        hazard model was used to build severity scores for
                        health status pre- and 2 years post-transplant. Age,
                        gender, race, and comorbidities were also examined. A t-test and ANCOVA were used to examine
                        differences pre- and post-LT. Results showed that
                        better health status pre-transplant was not statistically significant associated with better health status
                        post-transplant. However, health status posttransplant was less variable than pre-transplant.
                        There was a statistically significant association between female gender and kidney severity with
                        worse health status post-transplant; thus, gender
                        and kidney disease may be associated with liver
                        transplant recipients’ wellbeing and play an important role in health status post-transplant.</p>
                        <p><a href="http://ceur-ws.org/Vol-2760/paper1.pdf" class="btn btn-secondary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Paper PDF</a></p>
					</div>
				</div><!--//modal-body-->
			</div><!--//modal-content-->
		</div><!--//modal-dialog-->
	</div><!--//modal-->

	<div class="modal modal-speaker modal-abstract-1" id="modal-abstract-1" tabindex="-1" role="dialog" aria-labelledby="abstract-1-ModalLabel" aria-hidden="true">
		<div class="modal-dialog">
			<div class="modal-content">
				<div class="modal-header">
					<button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
					<h4 id="abstract-1-ModalLabel" class="modal-title sr-only">Challenges of developing a natural language processing method with electronic health records to identify persons with chronic mobility disability</h4>
				</div>
				<div class="modal-body p-0">
					<div class="media flex-column flex-md-row theme-bg-light p-4 p-lg-5">
						<div class="media-body text-center text-md-left mx-auto">
							<h2 class="name mb-2">Challenges of developing a natural language processing method with electronic health records to identify persons with chronic mobility disability</h2>
							<div class="meta">Nicole Agaronnik, Charlotta Lindvall, Areej El-Jawahri, Wei He, Lisa Iezzoni </div>
                            <div class="meta"><i class="far fa-calendar-alt mr-2"></i>2:20 - 2:40AM UTC, January 7 2021</div>
						</div><!--//media-body-->
					</div><!--//media-->
					
					<div class="desc p-4 p-lg-5">
                        <p>
                        Research Objective:
                        To assess utility of applying natural language processing (NLP) to electronic health records (EHRs) to identify people with chronic mobility disability
                        </p>

                        <p>
                        Study Design:
                        We used EHRs from the Partners HealthCare Research Patient Data Repository (RPDR), which collects data across a large healthcare delivery system in eastern Massachusetts. Standard diagnosis codes identified patients 21-75 years old who were newly diagnosed with colorectal cancer between 2005-2017. Clinical Regex NLP software was applied to unstructured free text notes to identify keywords associated with wheelchair-use. We used a semi-automated review process of notes identified by Clinical Regex to confirm that keywords appeared in appropriate contexts. Directed content analysis of retrieved notes was used to confirm cases of true wheelchair-use, and assess chronicity, duration, and documentation quality.
                        </p>

                        <p>
                        Population Studied:
                        14,877 patients aged 21-75 years old, newly diagnosed with colorectal cancer between 2005-2017. Median age = 61 years, 52.3% male, 81.9% white, and 97.3% non-Hispanic
                        </p>

                        <p>
                        Principal Findings:
                        Patients were associated with 303,182 notes. NLP identified 1,482 (0.5%) notes containing 1+ keywords. These notes were associated with 420 patients (2.8% of colorectal cancer population). Of 1,482 notes, 286 notes (19.3%, representing 105 patients, 0.7% of population) documented reason for wheelchair-use and duration. Three themes emerged concerning documentation quality: (1) wheelchair keywords used in specific EHR context; (2) reasons for wheelchair not clearly stated; (3) duration of wheelchair-use not consistently documented.
                        </p>

                        <p>
                        Conclusions:
                        Though NLP improves efficiency of screening for wheelchair-use, manual chart review is still needed to confirm that flagged patients have chronic mobility disability.
                        </p>
					</div>
				</div><!--//modal-body-->
			</div><!--//modal-content-->
		</div><!--//modal-dialog-->
	</div><!--//modal-->

	<div class="modal modal-speaker modal-paper-2" id="modal-paper-2" tabindex="-1" role="dialog" aria-labelledby="paper-2-ModalLabel" aria-hidden="true">
		<div class="modal-dialog">
			<div class="modal-content">
				<div class="modal-header">
					<button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
					<h4 id="paper-2-ModalLabel" class="modal-title sr-only">Conversational Agent for Daily Living Assessment Coaching</h4>
				</div>
				<div class="modal-body p-0">
					<div class="media flex-column flex-md-row theme-bg-light p-4 p-lg-5">
						<div class="media-body text-center text-md-left mx-auto">
							<h2 class="name mb-2">Conversational Agent for Daily Living Assessment Coaching</h2>
							<div class="meta">Aditya Gaydhani, Raymond Finzel, Sheena Dufresne, Maria Gini, Serguei Pakhomov </div>
                            <div class="meta"><i class="far fa-calendar-alt mr-2"></i>2:40 - 3:00AM UTC, January 7 2021</div>
						</div><!--//media-body-->
					</div><!--//media-->
					
					<div class="desc p-4 p-lg-5">
                        <p>We present preliminary work-in-progress results of a project focused on developing a conversational agent system to help with training certified assessors in conducting assessments of functioning in activities of daily living. To date, we have designed a modular task-based conversational agent system and collected hypothetical dialogue data required for training system components as well as a knowledge base needed to generate a wide variety of synthetic profiles of &quot;individuals&quot; being assessed. One of the key components of the system is the topic tracking module that determines the current topic of the conversation. We report the results of experiments with several machine learning approaches to topic/domain classification. The highest accuracy of 83% was achieved with a bidirectional long short-term memory (BiLSTM) model with pre-trained GloVe embeddings. In addition to these results, we also discuss some of the other challenges that we have encountered so far and potential solutions that we are currently pursuing.</p>
                        <p><a href="http://ceur-ws.org/Vol-2760/paper2.pdf" class="btn btn-secondary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Paper PDF</a></p>
					</div>
				</div><!--//modal-body-->
			</div><!--//modal-content-->
		</div><!--//modal-dialog-->
	</div><!--//modal-->


	<div class="modal modal-speaker modal-paper-3" id="modal-paper-3" tabindex="-1" role="dialog" aria-labelledby="paper-3-ModalLabel" aria-hidden="true">
		<div class="modal-dialog">
			<div class="modal-content">
				<div class="modal-header">
					<button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
					<h4 id="paper-3-ModalLabel" class="modal-title sr-only">Person-Independent Multimodal Emotion Detection for Children with High-Functioning Autism</h4>
				</div>
				<div class="modal-body p-0">
					<div class="media flex-column flex-md-row theme-bg-light p-4 p-lg-5">
						<div class="media-body text-center text-md-left mx-auto">
							<h2 class="name mb-2">Person-Independent Multimodal Emotion Detection for Children with High-Functioning Autism</h2>
							<div class="meta">Annanda Sousa, Mathieu d’Aquin, Manel Zarrouk, Jennifer Holloway </div>
                            <div class="meta"><i class="far fa-calendar-alt mr-2"></i>12:10 - 12:30AM UTC, January 8 2021</div>
						</div><!--//media-body-->
					</div><!--//media-->
					
					<div class="desc p-4 p-lg-5">
                        <p>The use of affect-sensitive interfaces carries the promise of enhancing the human-computer interaction by delivering a system capable of identifying a user's emotions and adapt its content accordingly. Today's technology shows great potential to support children with autism, for example by using computer systems to improve their social skills. Generally, however, this technology does not encompass the potential of affect-sensitive interfaces. This is mainly due to Emotion Detection (ED) models built for the general population usually do not perform well when applied to children with autism, who express emotions differently. The aim of this project is therefore to build a person-independent Multimodal Emotion Detection system tailored for children with high-functioning autism for the ultimate goal of applying it to design affect-sensitive interfaces dedicated to children with autism. This is a work in progress and the project expects to build upon the current body of knowledge on methods to apply ED systems to this specific subset of the general population. We expect to apply the overall theoretical and practical design perspectives that arise from this research investigation (e.g. analysis of modalities and features extraction, behavioural cues based features, fusion layers and classifier techniques) to propose a guiding framework for future studies.</p>
                        <p><a href="http://ceur-ws.org/Vol-2760/paper3.pdf" class="btn btn-secondary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Paper PDF</a></p>
					</div>
				</div><!--//modal-body-->
			</div><!--//modal-content-->
		</div><!--//modal-dialog-->
	</div><!--//modal-->


	<div class="modal modal-speaker modal-paper-4" id="modal-paper-4" tabindex="-1" role="dialog" aria-labelledby="paper-4-ModalLabel" aria-hidden="true">
		<div class="modal-dialog">
			<div class="modal-content">
				<div class="modal-header">
					<button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
					<h4 id="paper-4-ModalLabel" class="modal-title sr-only">Assistive Mobile Application for the Blind</h4>
				</div>
				<div class="modal-body p-0">
					<div class="media flex-column flex-md-row theme-bg-light p-4 p-lg-5">
						<div class="media-body text-center text-md-left mx-auto">
							<h2 class="name mb-2">Assistive Mobile Application for the Blind</h2>
							<div class="meta">Ismail Sahak, Huey Fang Ong, Syuhada Abdul Rahman </div>
                            <div class="meta"><i class="far fa-calendar-alt mr-2"></i>12:30 - 12:50AM UTC, January 8 2021</div>
						</div><!--//media-body-->
					</div><!--//media-->
					
					<div class="desc p-4 p-lg-5">
                        <p>One of the challenges faced by blind people is the difficulty in identifying objects with concise in-formation. They could only rely on the senses of hearing, smell, taste or touch to engage and get some perspectives of objects. Hence, this paper presents a mobile application called Iris to aid blind people in “visualising” their surroundings with descriptive objects. Iris combines the multiple object detection and optical character recognition capabilities of Microsoft Computer Vision API to turns smartphones into assistive devices for the blind to use in their daily activities.</p>
                        <p><a href="http://ceur-ws.org/Vol-2760/paper4.pdf" class="btn btn-secondary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Paper PDF</a></p>
					</div>
				</div><!--//modal-body-->
			</div><!--//modal-content-->
		</div><!--//modal-dialog-->
	</div><!--//modal-->


	<div class="modal modal-speaker modal-paper-5" id="modal-paper-5" tabindex="-1" role="dialog" aria-labelledby="paper-5-ModalLabel" aria-hidden="true">
		<div class="modal-dialog">
			<div class="modal-content">
				<div class="modal-header">
					<button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
					<h4 id="paper-5-ModalLabel" class="modal-title sr-only">Privacy-Preserving Monitoring System with Ultra Low-Resolution Infrared Sensor</h4>
				</div>
				<div class="modal-body p-0">
					<div class="media flex-column flex-md-row theme-bg-light p-4 p-lg-5">
						<div class="media-body text-center text-md-left mx-auto">
							<h2 class="name mb-2">Privacy-Preserving Monitoring System with Ultra Low-Resolution Infrared Sensor</h2>
							<div class="meta">Miyuki Ogata, Shogo Murakami, Takumi Mikura, Ikuko Eguchi Yairi </div>
                            <div class="meta"><i class="far fa-calendar-alt mr-2"></i>2:10 - 2:30AM UTC, January 8 2021</div>
						</div><!--//media-body-->
					</div><!--//media-->
					
					<div class="desc p-4 p-lg-5">
                        <p>Action monitoring system used in households offers vital information for health monitoring particularly with aging residents. While visual inputs such as information provided by cameras can recognize the actions and position of a subject with high accuracy, they are not widely accepted due to privacy concerns. This paper proposes a DCNN for posture classification with the use of a low-resolution thermal sensor. The sensor aims to protect the subject’s privacy by capturing visual input in the infrared spectrum as well as having a low spatial resolution of 8x8 pixels. We consider simulation which recreates the experimental environment and produce artificial data for this postural-behavioral problem. The validity of this method is checked by considering 3 postures; standing, sitting, and laying down and cross-examining with field data. Additionally, we explore optimal position and angle of the sensor as well as the effects of color depth on accuracy. In our results we achieved over 93% classification accuracy by color conversion of the infrared array sensor image and successfully decreased loss due to displacement by DCNN. We discovered higher accuracies are achieved when the sensor is located 50cm below a subject’s height with a tilt angle of ±2°.</p>
                        <p><a href="http://ceur-ws.org/Vol-2760/paper5.pdf" class="btn btn-secondary btn-med mr-md-2 d-block d-md-inline-block mb-3 mb-md-0" target="_blank">Paper PDF</a></p>
					</div>
				</div><!--//modal-body-->
			</div><!--//modal-content-->
		</div><!--//modal-dialog-->
	</div><!--//modal-->



	<div class="modal modal-speaker modal-abstract-2" id="modal-abstract-2" tabindex="-1" role="dialog" aria-labelledby="abstract-2-ModalLabel" aria-hidden="true">
		<div class="modal-dialog">
			<div class="modal-content">
				<div class="modal-header">
					<button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
					<h4 id="abstract-2-ModalLabel" class="modal-title sr-only">Building a Mobility Dictionary for Whole-Person Functional Assessment</h4>
				</div>
				<div class="modal-body p-0">
					<div class="media flex-column flex-md-row theme-bg-light p-4 p-lg-5">
						<div class="media-body text-center text-md-left mx-auto">
							<h2 class="name mb-2">Building a Mobility Dictionary for Whole-Person Functional Assessment</h2>
							<div class="meta">Ayah Zirikly, Bart Desmet, Denis Newman-Griffis, Pei-Shu Ho, Jonathan Camacho Maldonado, Maryanne Sacco, Julia Porcino </div>
                            <div class="meta"><i class="far fa-calendar-alt mr-2"></i>2:30 - 2:50AM UTC, January 8 2021</div>
						</div><!--//media-body-->
					</div><!--//media-->
					
					<div class="desc p-4 p-lg-5">
                        <p>The International Classification of Functioning, Disability and Health (ICF) provides a coding standard for whole-person function, including mobility, with the aim to allow consistent reporting of function information. Adoption is low, however, in part for lack of terminologies that can ease and improve coding and automatic information extraction. In this work, we create a dictionary for mobility function information, by expanding a manually extracted seed set using a lexicon-based and embeddings-based approach. We show that a combination of both methodologies yields high recall on mobility terms (60% exact and 97% partial match), and a nearest neighbor approach based on word embeddings significantly outperforms lexicon-based expansion.</p>
					</div>
				</div><!--//modal-body-->
			</div><!--//modal-content-->
		</div><!--//modal-dialog-->
	</div><!--//modal-->



	<div class="modal modal-speaker modal-keynote" id="modal-keynote" tabindex="-1" role="dialog" aria-labelledby="keynote-ModalLabel" aria-hidden="true">
		<div class="modal-dialog">
			<div class="modal-content">
				<div class="modal-header">
					<button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
					<h4 id="keynote-ModalLabel" class="modal-title sr-only">Digital Health Sciences: from Discovery to Delivery in Health care AI</h4>
				</div>
				<div class="modal-body p-0">
					<div class="media flex-column flex-md-row theme-bg-light p-4 p-lg-5">
						<div class="media-body text-center text-md-left mx-auto">
							<h2 class="name mb-2">Digital Health Sciences: from Discovery to Delivery in Health care AI</h2>
							<div class="meta">Hongfang Liu, PhD (Mayo Clinic)</div>
                            <div class="meta"><i class="far fa-calendar-alt mr-2"></i>12:30 - 1:30AM UTC, January 7 2021</div>
						</div><!--//media-body-->
					</div><!--//media-->
					
					<div class="desc p-4 p-lg-5">
                        <p>The advancement of digital transformation has accelerated the adoption of Artificial Intelligence (AI) in health care. A stunning growth in the volume of information generated through routine practice, biomedical research, wearable devices and sensors together with the increasing availability of environmental and geospatial sensors developed on digital platforms is transforming health care towards learning health care system and precision medicine leveraging data science and AI techniques. However, the value of big data in health care is realized only when this raw information is converted into AI applications that changes practice. Deep learning approaches can process masses amount of raw data to generate insights which makes the dependence of expert knowledge in health care no longer important. In this talk, I will discuss healthcare AI in general and focus specifically on the importance of the people-centric view from the discovery to the delivery in health care AI.</p>
					</div>
				</div><!--//modal-body-->
			</div><!--//modal-content-->
		</div><!--//modal-dialog-->
	</div><!--//modal-->
	
	<!-- Javascript -->          
	<script src="assets/plugins/jquery-3.4.1.min.js"></script>
	<script src="assets/plugins/popper.min.js"></script>
	<script src="assets/plugins/bootstrap/js/bootstrap.min.js"></script>  
	<script src="assets/plugins/back-to-top.js"></script>
	<script src="assets/plugins/jquery.scrollTo.min.js"></script>
	<script src="assets/js/main.js"></script>  

</body>
</html> 

